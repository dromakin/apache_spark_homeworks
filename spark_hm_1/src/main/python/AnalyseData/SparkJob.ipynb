{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d5302a8-a0f1-45f8-9f25-06bdbb85085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pygeohash as gh\n",
    "from functools import reduce\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame, Row\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, TimestampType, ShortType, DateType, DoubleType\n",
    "from pyspark.sql.functions import col, when, row_number\n",
    "\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "from opencage.geocoder import InvalidInputError, RateLimitExceededError, UnknownError\n",
    "from pprint import pprint\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(\"SparkJob.py\"))))))\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "DATA_HOTELS = os.path.join(DATA_DIR, \"hotels\")\n",
    "DATA_WEATHER = os.path.join(DATA_DIR, \"weather\")\n",
    "\n",
    "GEOCODER_KEY = os.getenv(\"GEOCODER_KEY\", \"8566ce4a944a43b49d3d81f8c4202719\")\n",
    "\n",
    "\n",
    "hotel_schema = StructType(\n",
    "    [\n",
    "        StructField(\"Id\", StringType(), True),\n",
    "        StructField(\"Name\", StringType(), True),\n",
    "        StructField(\"Country\", StringType(), True),\n",
    "        StructField(\"City\", StringType(), True),\n",
    "        StructField(\"Address\", StringType(), True),\n",
    "        StructField(\"Latitude\", StringType(), True),\n",
    "        StructField(\"Longitude\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "weather_schema = StructType(\n",
    "    [\n",
    "        StructField(\"lng\", DoubleType(), True),\n",
    "        StructField(\"lat\", DoubleType(), True),\n",
    "        StructField(\"avg_tmpr_f\", DoubleType(), True),\n",
    "        StructField(\"avg_tmpr_c\", DoubleType(), True),\n",
    "        StructField(\"wthr_date\", StringType(), True),\n",
    "        StructField(\"wthr_year\", StringType(), True),\n",
    "        StructField(\"wthr_month\", StringType(), True),\n",
    "        StructField(\"wthr_day\", StringType(), True),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99186d5f-dc62-49c5-9d7b-8c0139c0a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_Spark():\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"Simple etl job\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    print(\"Spark Initialized\", \"\\n\")\n",
    "\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b02e061-e1e1-4b10-8f0f-f98d05f2f193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/dmitrii_romakin/PycharmProjects/m06_sparkbasics_python_azure/venv/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/09/20 11:55:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Initialized \n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = initialize_Spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read hotel data using os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf2a58-8564-4e1e-a0e4-93e24e019328",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotelsfiles = [os.path.join(DATA_HOTELS, f) for f in os.listdir(DATA_HOTELS) if os.path.isfile(os.path.join(DATA_HOTELS, f))]\n",
    "hotelsfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff2b62d-1f38-48bc-a764-d36f3e946b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://walkenho.github.io/merging-multiple-dataframes-in-pyspark/\n",
    "# https://mungingdata.com/pyspark/union-unionbyname-merge-dataframes/\n",
    "\n",
    "def loadDFWithSchema(spark, hotelfile):\n",
    "    df = spark \\\n",
    "        .read \\\n",
    "        .format(\"csv\") \\\n",
    "        .schema(hotel_schema) \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .load(hotelfile)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18801f2f-8eaf-42d7-a5c1-62c329f35cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "\n",
    "for file in hotelsfiles:\n",
    "    dfs.append(loadDFWithSchema(spark, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hotels = reduce(DataFrame.unionAll, dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hotels.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read hotel data using spark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_hotels = spark.read.csv(DATA_HOTELS + \"/*.csv.gz\", header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Work with hotels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hotels.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f22de-c4c7-4972-ab93-ecec8b617d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotels.first(), df_hotels.first().Id, type(df_hotels.first().Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b252d-920e-4a50-98e5-b4c131d34b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotels.filter(col(\"Latitude\").isNull() | col(\"Latitude\").rlike(\"NA\")).show(),\n",
    "df_hotels.filter(col(\"Longitude\").isNull() | col(\"Longitude\").rlike(\"NA\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Geocoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "geocoder = OpenCageGeocode(GEOCODER_KEY)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = geocoder.reverse_geocode(44.8303087, -0.5761911)\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# query = u'Bosutska ulica 10, Trnje, Zagreb, Croatia'\n",
    "query = u'189 Swans Falls Rd, Fryeburg'\n",
    "results = geocoder.geocode(query)\n",
    "\n",
    "print(u'%f;%f;%s;%s' % (results[0]['geometry']['lat'],\n",
    "                        results[0]['geometry']['lng'],\n",
    "                        results[0]['components']['country_code'],\n",
    "                        results[0]['annotations']['timezone']['name']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixing latitude"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "34"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_lat = [row.Id for row in df_hotels.filter(col(\"Latitude\").isNull() | col(\"Latitude\").rlike(\"NA\")).collect()]\n",
    "len(ids_lat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hotels.filter(col(\"Id\") == ids_lat[0]).collect()[0].Address"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def get_lat_by_row(row):\n",
    "    row_dict = row.asDict()\n",
    "    if row_dict.get(\"Id\") in ids_lat:\n",
    "        query = f'{row_dict.get(\"Address\")}, {row_dict.get(\"City\")}'\n",
    "        results = geocoder.geocode(query)\n",
    "        row_dict['Latitude'] = str(results[0]['geometry']['lat'])\n",
    "        newrow = Row(**row_dict)\n",
    "        return newrow\n",
    "    return row\n",
    "\n",
    "\n",
    "\n",
    "df_hotels_rdd = df_hotels.rdd\n",
    "df_hotels_rdd_new = df_hotels_rdd.map(lambda row: get_lat_by_row(row))\n",
    "df_hotels_lat = spark.createDataFrame(df_hotels_rdd_new)\n",
    "\n",
    "\n",
    "# for id in ids_lat:\n",
    "#     address = df_hotels.filter(col(\"Id\") == id).collect()[0].Address\n",
    "#     city = df_hotels.filter(col(\"Id\") == id).collect()[0].City\n",
    "#     print(df_hotels.filter(col(\"Id\") == id).collect()[0].Latitude)\n",
    "#     df_hotels = df_hotels.withColumn(\n",
    "#         \"Latitude\",\n",
    "#         when(\n",
    "#             col(\"Id\") == id,\n",
    "#             get_lat_by_address(address, city)\n",
    "#         ).otherwise(\"Latitude\")\n",
    "#     )\n",
    "#     print(df_hotels.filter(col(\"Id\") == id).collect()[0].Latitude)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hotels_lat.filter(col(\"Latitude\").isNull() | col(\"Latitude\").rlike(\"NA\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Change Latitude using Pandas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pandas_df = df.toPandas()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pandas_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nullids = list(pandas_df[(pandas_df['Latitude'].isnull()) | (pandas_df['Latitude'] == 'NA')].Id)\n",
    "print(nullids)\n",
    "pandas_df[(pandas_df['Latitude'].isnull()) | (pandas_df['Latitude'] == 'NA')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_lat_by_address(address, city):\n",
    "    query = f'{address}, {city}'\n",
    "    results = geocoder.geocode(query)\n",
    "    # print(query, str(results[0]['geometry']['lat']))\n",
    "    return str(results[0]['geometry']['lat'])\n",
    "\n",
    "nullLatitudeIds = list(pandas_df[(pandas_df['Latitude'].isnull()) | (pandas_df['Latitude'] == 'NA')].Id)\n",
    "\n",
    "for id in nullLatitudeIds:\n",
    "    address = pandas_df.loc[pandas_df.Id == id, 'Address'].values[0]\n",
    "    city = pandas_df.loc[pandas_df.Id == id, 'City'].values[0]\n",
    "    pandas_df.loc[pandas_df.Id == id, 'Latitude'] = get_lat_by_address(address, city)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixing longitude"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "34"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_lng = [row.Id for row in df_hotels_lat.filter(col(\"Longitude\").isNull() | col(\"Longitude\").rlike(\"NA\")).collect()]\n",
    "len(ids_lng)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hotels_lat.filter(col(\"Id\") == ids_lng[0]).collect()[0].Address"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def get_lng_by_address(row):\n",
    "    row_dict = row.asDict()\n",
    "    if row_dict.get(\"Id\") in ids_lng:\n",
    "        query = f'{row_dict.get(\"Address\")}, {row_dict.get(\"City\")}'\n",
    "        results = geocoder.geocode(query)\n",
    "        row_dict['Longitude'] = str(results[0]['geometry']['lng'])\n",
    "        newrow = Row(**row_dict)\n",
    "        return newrow\n",
    "    return row\n",
    "\n",
    "\n",
    "\n",
    "df_hotels_lat_rdd = df_hotels_lat.rdd\n",
    "df_hotels_lat_lng_rdd_new = df_hotels_lat_rdd.map(lambda row: get_lng_by_address(row))\n",
    "df_hotels_new = spark.createDataFrame(df_hotels_lat_lng_rdd_new)\n",
    "\n",
    "# for id in ids_lng:\n",
    "#     address = df_hotels.filter(col(\"Id\") == id).collect()[0].Address\n",
    "#     city = df_hotels.filter(col(\"Id\") == id).collect()[0].City\n",
    "#     print(df_hotels.filter(col(\"Id\") == id).collect()[0].Longitude)\n",
    "#     df_hotels = df_hotels.withColumn(\n",
    "#         \"Longitude\",\n",
    "#         when(\n",
    "#             col(\"Id\") == id,\n",
    "#             get_lng_by_address(address, city)\n",
    "#         ).otherwise(\"NA\")\n",
    "#     )\n",
    "#     print(df_hotels.filter(col(\"Id\") == id).collect()[0].Longitude)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hotels_new.filter(col(\"Longitude\").isNull() | col(\"Longitude\").rlike(\"NA\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Change Longitude using Pandas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_lng_by_address(address, city):\n",
    "    query = f'{address}, {city}'\n",
    "    results = geocoder.geocode(query)\n",
    "    print(query, str(results[0]['geometry']['lng']))\n",
    "    return str(results[0]['geometry']['lng'])\n",
    "\n",
    "nullLongitudeIds = list(pandas_df[(pandas_df['Longitude'].isnull()) | (pandas_df['Longitude'] == 'NA')].Id)\n",
    "\n",
    "for id in nullLongitudeIds:\n",
    "    address = pandas_df.loc[pandas_df.Id == id, 'Address'].values[0]\n",
    "    city = pandas_df.loc[pandas_df.Id == id, 'City'].values[0]\n",
    "    pandas_df.loc[pandas_df.Id == id, 'Longitude'] = get_lng_by_address(address, city)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RESULT\n",
    "pandas_df[(pandas_df['Latitude'].isnull()) | (pandas_df['Latitude'] == 'NA')],\\\n",
    "pandas_df[(pandas_df['Longitude'].isnull()) | (pandas_df['Longitude'] == 'NA')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GEOHASH"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pandas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pandas_df['Geohash'] = pandas_df.apply(lambda x: gh.encode(float(x.Latitude), float(x.Longitude), precision=4), axis=1)\n",
    "pandas_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_df = spark.createDataFrame(pandas_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_df.filter(col(\"Latitude\").isNull()).show(), new_df.filter(col(\"Longitude\").isNull()).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PySpark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def geohash_function(row):\n",
    "    row_dict = row.asDict()\n",
    "    row_dict['Geohash'] = gh.encode(float(row_dict.get(\"Latitude\")), float(row_dict.get(\"Longitude\")), precision=4)\n",
    "    newrow = Row(**row_dict)\n",
    "    return newrow\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_hotels_new_rdd = df_hotels_new.rdd\n",
    "df_hotels_rdd_new = df_hotels_new_rdd.map(lambda row: geohash_function(row))\n",
    "df_hotels_geohash = spark.createDataFrame(df_hotels_rdd_new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hotels_geohash.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hotels_geohash.filter(col(\"Latitude\").isNull() | col(\"Latitude\").rlike(\"NA\")).show(),\n",
    "df_hotels_geohash.filter(col(\"Longitude\").isNull() | col(\"Longitude\").rlike(\"NA\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start work with weather"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Weather import files using os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weatherfiles = list()\n",
    "\n",
    "ignorelist = ['.DS_Store',]\n",
    "\n",
    "for root, d_names, f_names in os.walk(DATA_WEATHER):\n",
    "    for f in f_names:\n",
    "        if f not in ignorelist and 'crc' not in f:\n",
    "            weatherfiles.append(os.path.join(root, f))\n",
    "\n",
    "# 553\n",
    "len(weatherfiles)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs_weather_list = list()\n",
    "\n",
    "for file in weatherfiles:\n",
    "    dfs_weather_list.append(spark.read.parquet(file))\n",
    "\n",
    "len(dfs_weather_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_weather = reduce(DataFrame.unionAll, dfs_weather_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_weather.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Weather import files using spark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df_weather = spark.read.parquet(DATA_WEATHER, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_weather.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_weather.show(4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Geohash weather"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def geohash_function(row):\n",
    "    row_dict = row.asDict()\n",
    "    row_dict['Geohash'] = gh.encode(float(row_dict.get(\"lat\")), float(row_dict.get(\"lng\")), precision=4)\n",
    "    newrow = Row(**row_dict)\n",
    "    return newrow\n",
    "\n",
    "df_weather_rdd = df_weather.rdd\n",
    "df_weather_rdd_new = df_weather_rdd.map(lambda row: geohash_function(row))\n",
    "df_weather_geohash = spark.createDataFrame(df_weather_rdd_new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_weather_geohash.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filtering weather df using geohash in hotels df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_hotels_geohash_list = [str(row['Geohash']) for row in df_hotels_geohash.collect()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(df_hotels_geohash_list), df_hotels_geohash.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df_weather_geohash_filter = df_weather_geohash.filter(df_weather_geohash.Geohash.isin(df_hotels_geohash_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_weather_geohash_filter.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_weather_geohash_filter.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Join dfs - weather filtering by hotels' geohash\n",
    "\n",
    "### Inner Join"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "result_df_inner = df_hotels_geohash.join(df_weather_geohash_filter, [\"Geohash\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "2344623"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_inner.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------------+-------+-------+-------------+---------+-----------+--------+-------+----------+----------+----------+----+-----+---+\n",
      "|Geohash|        Id|               Name|Country|   City|      Address| Latitude|  Longitude|     lng|    lat|avg_tmpr_f|avg_tmpr_c| wthr_date|year|month|day|\n",
      "+-------+----------+-------------------+-------+-------+-------------+---------+-----------+--------+-------+----------+----------+----------+----+-----+---+\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.582|42.0163|      73.1|      22.8|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.524|42.0251|      73.6|      23.1|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.467|42.0339|      75.3|      24.1|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.409|42.0426|      76.1|      24.5|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.352|42.0514|      77.2|      25.1|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.651|42.0502|      75.5|      24.2|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.593| 42.059|      73.3|      22.9|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.536|42.0678|      74.0|      23.3|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.479|42.0765|      70.7|      21.5|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.421|42.0853|      72.8|      22.7|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.364| 42.094|      77.0|      25.0|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.663|42.0928|      72.4|      22.4|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.605|42.1016|      76.8|      24.9|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.548|42.1104|      79.0|      26.1|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345| -122.49|42.1192|      73.6|      23.1|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.433| 42.128|      72.6|      22.6|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.375|42.1367|      76.8|      24.9|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.675|42.1355|      73.4|      23.0|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.617|42.1443|      77.5|      25.3|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345| -122.56|42.1531|      78.4|      25.8|2017-08-29|2017|    8| 29|\n",
      "|   9r2z|8589934594|Holiday Inn Express|     US|Ashland|555 Clover Ln|42.183544|-122.663345|-122.502|42.1619|      73.0|      22.8|2017-08-29|2017|    8| 29|\n",
      "+-------+----------+-------------------+-------+-------+-------------+---------+-----------+--------+-------+----------+----------+----------+----+-----+---+\n",
      "only showing top 21 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_df_inner.show(21)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Left Join"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df_lj_f = df_hotels_geohash.join(df_weather_geohash_filter, [\"Geohash\"], how='left_outer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df_lj_f.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df_lj_f.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Difference between result_df_inner_f & result_df_lj_f"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_dif = result_df_lj_f.subtract(result_df_inner_f)\n",
    "df_dif.show(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Join dfs - without filtering\n",
    "\n",
    "join(self, other, on=None, how=None)\n",
    "\n",
    "* param other: Right side of the join\n",
    "* param on: a string for the join column name\n",
    "* param how: default inner. Must be one of inner, cross, outer,full, full_outer, left, left_outer, right, right_outer,left_semi, and left_anti."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inner Join"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df_inner = df_hotels_geohash.join(df_weather_geohash, [\"Geohash\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df_inner.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df_inner.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Left Join"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df_lj = df_hotels_geohash.join(df_weather_geohash, [\"Geohash\"], how='left_outer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df_lj.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df_lj.show(3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Difference between result_df_inner & result_df_lj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_dif = result_df_lj.subtract(result_df_inner)\n",
    "df_dif.show(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}